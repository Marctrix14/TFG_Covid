{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Marc Padrós Jiménez\n",
    "# Bachelor's Final Degree Project\n",
    "# Date: 27th April 2022\n",
    "\n",
    "# fastai version on laptop is 2.6.0\n",
    "# On Desktop is 2.5.3\n",
    "\n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from Libraries.grid_bboxes_library import * \n",
    "\n",
    "from Libraries.lungs_detection_library import * \n",
    "\n",
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the detected predicted lungs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungsDetectorModel = setupLungsLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictedLungs = lungsDetectorModel.get_preds()\n",
    "# predictedLungs = tuple with 2 elements\n",
    "# 1st element of the tuple is a TensorBase\n",
    "# 2nd element of the tuple is a TensorBBox of size nValidationImages x 8 (8 = total number of coords. for image)\n",
    "# the first 4 coords of a TensorBBox element refer to the bbox of the left lung\n",
    "# the last 4 coords of a TensorBBox element refer to the bbox of the right lung \n",
    "\n",
    "predictedLungs = ((predictedLungs[1] + 1) / 2).numpy()\n",
    "# (preds + 1) is used to make negative predictions turn into positive \n",
    "# NOTE: Why is ((preds + 1) divided by 2? are the predictions too big (I GET THAT IT'S A NORMALIZATION OF PREDICTIONS)\n",
    "# numpy() converts to a ndarray Example size: (83,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the grids related to pleural effusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLungsPaths = lungsDetectorModel.dls.valid_ds.items\n",
    "\n",
    "gridsPath = \"gridsPleuralEffusion/\"\n",
    "\n",
    "# Before storing the grids, remove the content of the path where grids will be stored\n",
    "import shutil\n",
    "shutil.rmtree(gridsPath)\n",
    "\n",
    "for i in range(len(predictedLungsPaths)):\n",
    "    imageFullName = predictedLungsPaths[i].name # it contains also the extension\n",
    "    \n",
    "    imagePath = '../../../Lungs_detection/Datasets/roi_detection_subset/train_val/' + imageFullName\n",
    "\n",
    "    imgRes = cv2.imread(imagePath) \n",
    "\n",
    "    # NOTE: I read again the BW image that was previously readen because \n",
    "    # I need it as an array, not as a PILImage type to be able to access the pixels values \n",
    "    imgOri = cv2.imread(imagePath, cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "    leftLung = predictedLungs[i][0:4] * [imgOri.shape[0], imgOri.shape[1], imgOri.shape[0], imgOri.shape[1]]\n",
    "    # convert a TensorBBox to a numpy array, so that, we can access each coord as a flot\n",
    "    rightLung = predictedLungs[i][4:8] * [imgOri.shape[0], imgOri.shape[1], imgOri.shape[0], imgOri.shape[1]]\n",
    "\n",
    "    gridsLungLeft = gridBbox(leftLung, imgRes, imgOri, 3, 3) # grid bbox left in the X-ray image / right in the body\n",
    "    gridsLungRight = gridBbox(rightLung, imgRes, imgOri, 3, 3) # grid bbox right\n",
    "\n",
    "    #plt.imshow(imgRes)\n",
    "\n",
    "    #plt.figure()\n",
    "\n",
    "    #f, axarr = plt.subplots(1,2) \n",
    "\n",
    "    imageName = predictedLungsPaths[i].stem # it doesn't contain the extension \n",
    "\n",
    "    gridsImagePath = gridsPath + imageName + '/' \n",
    "\n",
    "    os.makedirs(gridsImagePath, exist_ok=True)\n",
    "\n",
    "    #axarr[0].imshow(gridsLungLeft[6])\n",
    "    cv2.imwrite(os.path.join(gridsImagePath,'D3.png'), gridsLungLeft[6])\n",
    "\n",
    "    #axarr[1].imshow(gridsLungRight[8])\n",
    "    cv2.imwrite(os.path.join(gridsImagePath,'E3.png'), gridsLungRight[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify grids as normal or pleural effusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(gridImage):\n",
    "    im_width = 40\n",
    "    im_height = 40\n",
    "    img = gridImage\n",
    "    img.thumbnail((im_width, im_height)) # scale the image to a size not larger than im_width x im_height\n",
    "    x = img_to_array(img)  \n",
    "    x = np.resize(x,(1,40, 40, 1)) # I have to call resize() instead of reshape() because img.thumbnail doesn't return a 40x40 image\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the learned model from the Github repo: https://github.com/ashok133/Pleural-Effusion-Detection\n",
    "import csv\n",
    "\n",
    "model = keras.models.load_model(\"../CNN_model/dataset/train_test/models/effusion_model_v1_scratch.h5\")\n",
    "\n",
    "test_effusion_images_dir = gridsPath\n",
    "\n",
    "test_effusion_images = [imageFolder for imageFolder in os.listdir(test_effusion_images_dir)]\n",
    "\n",
    "prediction_effusion = []\n",
    "\n",
    "# Create a CSV file where to store the pleural effusion predictions results \n",
    "with open('pleural_effusion_results_v1_scratch.csv', 'w', newline='') as csvFile:\n",
    "  fieldnames = ['image_id', 'D3_prediction', 'E3_prediction']\n",
    "  writer = csv.DictWriter(csvFile, fieldnames=fieldnames)\n",
    "  writer.writeheader()\n",
    "\n",
    "  for imageId in test_effusion_images:\n",
    "    imagePath = test_effusion_images_dir + imageId + '/'\n",
    "    gridsImages = [load_img(imagePath+gridName, grayscale=True) for gridName in os.listdir(imagePath)] # collect images of the grids where pleural effusion can be located  \n",
    "    # imageGrids contains one grid image related to the left lung (\"D3.png\") and another related to the right lung (\"E3.png\")\n",
    "    effusion_array = [reshape(grid) for grid in gridsImages] # reshape each grid size to the input size of the CNN \"model\"\n",
    "    prediction_effusion.extend(\"Effusion\" if model.predict(effusion)[0][0] > 0.5 else \"Normal\" for effusion in effusion_array)\n",
    "    # Update CSV file\n",
    "    writer.writerow({'image_id': imageId, 'D3_prediction': prediction_effusion[-2], 'E3_prediction': prediction_effusion[-1]})\n",
    "    # -2 for D3 because D3 is alphabetically before E3, so, it's processed first "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a0658ff7a6d5ab0a4ef2d422b5e5441971028a0ce30ba0283631efe18810246"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
